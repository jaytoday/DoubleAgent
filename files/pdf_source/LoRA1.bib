@inproceedings{dolan-brockett-2005-automatically,
    title = "Automatically Constructing a Corpus of Sentential Paraphrases",
    author = "Dolan, William B.  and
      Brockett, Chris",
    booktitle = "Proceedings of the Third International Workshop on Paraphrasing ({IWP}2005)",
    year = "2005",
    url = "https://aclanthology.org/I05-5002",
}

@inproceedings{socher-etal-2013-recursive,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D13-1170",
    pages = "1631--1642",
}

@article{Cer_2017,
   title={SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and
            Crosslingual Focused Evaluation},
   url={http://dx.doi.org/10.18653/v1/S17-2001},
   DOI={10.18653/v1/s17-2001},
   journal={Proceedings of the 11th International Workshop on Semantic Evaluation
          (SemEval-2017)},
   publisher={Association for Computational Linguistics},
   author={Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia},
   year={2017}
}

@article{warstadt2018neural,
    title={Neural Network Acceptability Judgments},
    author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},
    journal={arXiv preprint arXiv:1805.12471},
    year={2018}
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@misc{liu2019roberta,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2020superglue,
      title={SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems}, 
      author={Alex Wang and Yada Pruksachatkun and Nikita Nangia and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
      year={2020},
      eprint={1905.00537},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{he2021deberta,
      title={DeBERTa: Decoding-enhanced BERT with Disentangled Attention}, 
      author={Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
      year={2021},
      eprint={2006.03654},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{zaken2021bitfit,
      title={BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models}, 
      author={Elad Ben Zaken and Shauli Ravfogel and Yoav Goldberg},
      year={2021},
      eprint={2106.10199},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{ruckle2020adapterdrop,
      title={AdapterDrop: On the Efficiency of Adapters in Transformers}, 
      author={Andreas Rücklé and Gregor Geigle and Max Glockner and Tilman Beck and Jonas Pfeiffer and Nils Reimers and Iryna Gurevych},
      year={2020},
      eprint={2010.11918},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{pfeiffer2021adapterfusion,
      title={AdapterFusion: Non-Destructive Task Composition for Transfer Learning}, 
      author={Jonas Pfeiffer and Aishwarya Kamath and Andreas Rücklé and Kyunghyun Cho and Iryna Gurevych},
      year={2021},
      eprint={2005.00247},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{wang2019glue,
      title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding}, 
      author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
      year={2019},
      eprint={1804.07461},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{ba2016layer,
      title={Layer Normalization}, 
      author={Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
      year={2016},
      eprint={1607.06450},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


@inproceedings{lin-etal-2020-exploring,
    title = "Exploring Versatile Generative Language Model Via Parameter-Efficient Transfer Learning",
    author = "Lin, Zhaojiang  and
      Madotto, Andrea  and
      Fung, Pascale",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.41",
    doi = "10.18653/v1/2020.findings-emnlp.41",
    pages = "441--459",
    abstract = "Fine-tuning pre-trained generative language models to down-stream language generation tasks has shown promising results. However, this comes with the cost of having a single, large model for each task, which is not ideal in low-memory/power scenarios (e.g., mobile). In this paper, we propose an effective way to fine-tune multiple down-stream generation tasks simultaneously using a single, large pretrained model. The experiments on five diverse language generation tasks show that by just using an additional 2-3{\%} parameters for each task, our model can maintain or even improve the performance of fine-tuning the whole model.",
}


@misc{denil2014predicting,
      title={Predicting Parameters in Deep Learning}, 
      author={Misha Denil and Babak Shakibi and Laurent Dinh and Marc'Aurelio Ranzato and Nando de Freitas},
      year={2014},
      eprint={1306.0543},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{khodak2021initialization,
      title={Initialization and Regularization of Factorized Neural Layers}, 
      author={Mikhail Khodak and Neil Tenenholtz and Lester Mackey and Nicolò Fusi},
      year={2021},
      eprint={2105.01029},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


@misc{mahabadi2021compacter,
      title={Compacter: Efficient Low-Rank Hypercomplex Adapter Layers}, 
      author={Rabeeh Karimi Mahabadi and James Henderson and Sebastian Ruder},
      year={2021},
      eprint={2106.04647},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{lepikhin2020gshard,
      title={GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding}, 
      author={Dmitry Lepikhin and HyoukJoong Lee and Yuanzhong Xu and Dehao Chen and Orhan Firat and Yanping Huang and Maxim Krikun and Noam Shazeer and Zhifeng Chen},
      year={2020},
      eprint={2006.16668},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{shoeybi2020megatronlm,
      title={Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism}, 
      author={Mohammad Shoeybi and Mostofa Patwary and Raul Puri and Patrick LeGresley and Jared Casper and Bryan Catanzaro},
      year={2020},
      eprint={1909.08053},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{loshchilov2019decoupled,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@misc{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@article{allen2020feature,
  title={Feature purification: How adversarial training performs robust deep learning},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2005.10190},
  year={2020}
}



@inproceedings{dist,
  author={Jihun Ham and Daniel D. Lee},
  title={Grassmann discriminant analysis: a unifying view on subspace-based learning},
  year={2008},
  cdate={1199145600000},
  pages={376-383},
  url={https://doi.org/10.1145/1390156.1390204},
  booktitle={ICML},
}



@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={6000--6010},
  year={2017}
}
@article{DBLP:journals/corr/abs-1911-12237,
  author    = {Bogdan Gliwa and
               Iwona Mochol and
               Maciej Biesek and
               Aleksander Wawer},
  title     = {SAMSum Corpus: {A} Human-annotated Dialogue Dataset for Abstractive
               Summarization},
  journal   = {CoRR},
  volume    = {abs/1911.12237},
  year      = {2019},
  url       = {http://arxiv.org/abs/1911.12237},
  archivePrefix = {arXiv},
  eprint    = {1911.12237},
  timestamp = {Tue, 03 Dec 2019 20:41:07 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1911-12237.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-1709-00103,
  author    = {Victor Zhong and
               Caiming Xiong and
               Richard Socher},
  title     = {Seq2SQL: Generating Structured Queries from Natural Language using
               Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1709.00103},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.00103},
  archivePrefix = {arXiv},
  eprint    = {1709.00103},
  timestamp = {Mon, 13 Aug 2018 16:48:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-00103.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{williams-etal-2018-broad,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-1101",
    doi = "10.18653/v1/N18-1101",
    pages = "1112--1122",
    abstract = "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.",
}

@article{DBLP:journals/corr/abs-1808-07042,
  author    = {Siva Reddy and
               Danqi Chen and
               Christopher D. Manning},
  title     = {CoQA: {A} Conversational Question Answering Challenge},
  journal   = {CoRR},
  volume    = {abs/1808.07042},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.07042},
  archivePrefix = {arXiv},
  eprint    = {1808.07042},
  timestamp = {Sun, 02 Sep 2018 15:01:56 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-07042.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1806-03822,
  author    = {Pranav Rajpurkar and
               Robin Jia and
               Percy Liang},
  title     = {Know What You Don't Know: Unanswerable Questions for SQuAD},
  journal   = {CoRR},
  volume    = {abs/1806.03822},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.03822},
  archivePrefix = {arXiv},
  eprint    = {1806.03822},
  timestamp = {Mon, 13 Aug 2018 16:48:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-03822.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{novikova2017e2e,
  title={The E2E dataset: New challenges for end-to-end generation},
  author={Novikova, Jekaterina and Du{\v{s}}ek, Ond{\v{r}}ej and Rieser, Verena},
  journal={arXiv preprint arXiv:1706.09254},
  year={2017}
}

@inproceedings{gardent2017webnlg,
  title={The WebNLG challenge: Generating text from RDF data},
  author={Gardent, Claire and Shimorina, Anastasia and Narayan, Shashi and Perez-Beltrachini, Laura},
  booktitle={Proceedings of the 10th International Conference on Natural Language Generation},
  pages={124--133},
  year={2017}
}
@InProceedings{pmlr-v97-houlsby19a, title = {Parameter-Efficient Transfer Learning for {NLP}}, author = {Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain}, booktitle = {Proceedings of the 36th International Conference on Machine Learning}, pages = {2790--2799}, year = {2019}, editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, volume = {97}, series = {Proceedings of Machine Learning Research}, month = {09--15 Jun}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v97/houlsby19a/houlsby19a.pdf},  
}

@article{nan2020dart,
  title={Dart: Open-domain structured data record to text generation},
  author={Nan, Linyong and Radev, Dragomir and Zhang, Rui and Rau, Amrit and Sivaprasad, Abhinand and Hsieh, Chiachun and Tang, Xiangru and Vyas, Aadit and Verma, Neha and Krishna, Pranav and others},
  journal={arXiv preprint arXiv:2007.02871},
  year={2020}
}

@article{sellam2020bleurt,
  title={BLEURT: Learning robust metrics for text generation},
  author={Sellam, Thibault and Das, Dipanjan and Parikh, Ankur P},
  journal={arXiv preprint arXiv:2004.04696},
  year={2020}
}

@inproceedings{povey2018semi,
  title={Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks.},
  author={Povey, Daniel and Cheng, Gaofeng and Wang, Yiming and Li, Ke and Xu, Hainan and Yarmohammadi, Mahsa and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  pages={3743--3747},
  year={2018}
}

@article{oymak2019generalization,
  title={Generalization guarantees for neural networks via harnessing the low-rank structure of the jacobian},
  author={Oymak, Samet and Fabian, Zalan and Li, Mingchen and Soltanolkotabi, Mahdi},
  journal={arXiv preprint arXiv:1906.05392},
  year={2019}
}


@inproceedings{als18dnn,
	title        = {A Convergence Theory for Deep Learning via Over-Parameterization},
	author       = {{Allen-Zhu}, Zeyuan and Li, Yuanzhi and Song, Zhao},
	year         = 2019,
	booktitle    = {ICML},
	note         = {Full version available at \url{http://arxiv.org/abs/1811.03962}}
}
@inproceedings{li2018learning,
	title        = {Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data},
	author       = {Li, Yuanzhi and Liang, Yingyu},
	year         = 2018,
	booktitle    = {Advances in Neural Information Processing Systems}
}



@article{ghorbani2020neural,
  title={When do neural networks outperform kernel methods?},
  author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  journal={arXiv preprint arXiv:2006.13409},
  year={2020}
}
@inproceedings{AL2019-resnet,
	title        = {{What Can ResNet Learn Efficiently, Going Beyond Kernels?}},
	author       = {{Allen-Zhu}, Zeyuan and Li, Yuanzhi},
	year         = 2019,
	booktitle    = {NeurIPS},
	note         = {Full version available at \url{http://arxiv.org/abs/1905.10337}}
}


@article{allen2020backward,
	title        = {Backward Feature Correction: How Deep Learning Performs Deep Learning},
	author       = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2001.04413}
}




@inproceedings{zhao2016low,
  title={Low-rank plus diagonal adaptation for deep neural networks},
  author={Zhao, Yong and Li, Jinyu and Gong, Yifan},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5005--5009},
  year={2016},
  organization={IEEE}
}


@inproceedings{zhang2014extracting,
  title={Extracting deep neural network bottleneck features using low-rank matrix factorization},
  author={Zhang, Yu and Chuangsuwanich, Ekapol and Glass, James},
  booktitle={2014 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={185--189},
  year={2014},
  organization={IEEE}
}

@article{jaderberg2014speeding,
  title={Speeding up convolutional neural networks with low rank expansions},
  author={Jaderberg, Max and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1405.3866},
  year={2014}
}
@inproceedings{sainath2013low,
  title={Low-rank matrix factorization for deep neural network training with high-dimensional output targets},
  author={Sainath, Tara N and Kingsbury, Brian and Sindhwani, Vikas and Arisoy, Ebru and Ramabhadran, Bhuvana},
  booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
  pages={6655--6659},
  year={2013},
  organization={IEEE}
}
@article{grasedyck2013literature,
  title={A literature survey of low-rank tensor approximation techniques},
  author={Grasedyck, Lars and Kressner, Daniel and Tobler, Christine},
  journal={GAMM-Mitteilungen},
  volume={36},
  number={1},
  pages={53--78},
  year={2013},
  publisher={Wiley Online Library}
}



@inproceedings{li2018algorithmic,
  title={Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations},
  author={Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang},
  booktitle={Conference On Learning Theory},
  pages={2--47},
  year={2018},
  organization={PMLR}
}
@article{cai2010singular,
  title={A singular value thresholding algorithm for matrix completion},
  author={Cai, Jian-Feng and Cand{\`e}s, Emmanuel J and Shen, Zuowei},
  journal={SIAM Journal on optimization},
  volume={20},
  number={4},
  pages={1956--1982},
  year={2010},
  publisher={SIAM}
}
@inproceedings{li2016recovery,
  title={Recovery guarantee of weighted low-rank approximation via alternating minimization},
  author={Li, Yuanzhi and Liang, Yingyu and Risteski, Andrej},
  booktitle={International Conference on Machine Learning},
  pages={2358--2367},
  year={2016},
  organization={PMLR}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}